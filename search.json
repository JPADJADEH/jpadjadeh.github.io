[
  {
    "objectID": "Assignment1.html",
    "href": "Assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Anscombe’s Quartet shows that datasets can share nearly identical summary statistics (means, variances, correlations, and regression lines) yet have very different relationships when graphed. One series is roughly linear with noise, another is clearly non-linear (curved), another is driven by an outlier, and the last has vertical clustering forced by a high-leverage point.\nWhy this matters: Relying only on summary numbers can be misleading.\nBest practice: Always visualize the data (e.g., scatterplots) before and after modeling to catch:\n- Outliers / high-leverage points\n- Non-linear patterns\n- Heterogeneity or clusters\n\n# Load dataset\ndata(anscombe)\n\n# Build formulas and fit models\nff &lt;- y ~ x\nmods &lt;- setNames(vector(\"list\", 4), paste0(\"lm\", 1:4))\nfor (i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  mods[[i]] &lt;- lm(ff, data = anscombe)\n}\n\n# Panel layout and margins\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma = c(0, 0, 2, 0))\n\n# Plot 4 panels with regression lines\nfor (i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"blue\")\n}\n\nmtext(\"Anscombe's 4 Regression Data Sets\", outer = TRUE, cex = 1.3)\n\n\n\n\n\n\n\npar(op)"
  },
  {
    "objectID": "Assignment1.html#q1.-analyzing-anscombes-plots",
    "href": "Assignment1.html#q1.-analyzing-anscombes-plots",
    "title": "Assignment 1",
    "section": "",
    "text": "Anscombe’s Quartet shows that datasets can share nearly identical summary statistics (means, variances, correlations, and regression lines) yet have very different relationships when graphed. One series is roughly linear with noise, another is clearly non-linear (curved), another is driven by an outlier, and the last has vertical clustering forced by a high-leverage point.\nWhy this matters: Relying only on summary numbers can be misleading.\nBest practice: Always visualize the data (e.g., scatterplots) before and after modeling to catch:\n- Outliers / high-leverage points\n- Non-linear patterns\n- Heterogeneity or clusters\n\n# Load dataset\ndata(anscombe)\n\n# Build formulas and fit models\nff &lt;- y ~ x\nmods &lt;- setNames(vector(\"list\", 4), paste0(\"lm\", 1:4))\nfor (i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  mods[[i]] &lt;- lm(ff, data = anscombe)\n}\n\n# Panel layout and margins\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma = c(0, 0, 2, 0))\n\n# Plot 4 panels with regression lines\nfor (i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"blue\")\n}\n\nmtext(\"Anscombe's 4 Regression Data Sets\", outer = TRUE, cex = 1.3)\n\n\n\n\n\n\n\npar(op)"
  },
  {
    "objectID": "Assignment1.html#q.1-analyzing-anscombes-plots",
    "href": "Assignment1.html#q.1-analyzing-anscombes-plots",
    "title": "Assignment 1",
    "section": "Q.1 Analyzing Anscombe’s Plots",
    "text": "Q.1 Analyzing Anscombe’s Plots\nAnscombe’s Quartet teaches us that data can look the same in numbers but tell very different stories when you make a graph. All four datasets have the same averages, correlations, and regression lines, but the plots show one is a straight line, another is curved, and others are shaped by outliers.\nThe problem is that if we only look at numbers, we may miss these hidden patterns and make wrong conclusions.\nSolution: Always graph the data before and after running models. Simple plots like scatterplots can reveal issues such as:\n- Outliers\n- Non-linear trends\n- Unusual points"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Data_Visualization/Assignments/Assignment1.html",
    "href": "Data_Visualization/Assignments/Assignment1.html",
    "title": "Assignment 1: Data Visualization",
    "section": "",
    "text": "Anscombe’s Quartet teaches us that data can look the same in numbers but tell very different stories when you make a graph. All four datasets have the same averages, correlations, and regression lines, but the plots show one is a straight line, another is curved, and others are shaped by outliers.\nThe problem: If we only look at numbers, we may miss these hidden patterns and make wrong conclusions.\nThe solution: Always graph the data before and after running models. Simple plots like scatterplots can reveal issues like outliers, non-linear trends, or unusual points.\n\n\n\n# Load Anscombe's data\ndata(anscombe)\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n\n\n\n\n\n# Create four model objects\nlm1 &lt;- lm(y1 ~ x1, data=anscombe)\nlm2 &lt;- lm(y2 ~ x2, data=anscombe)\nlm3 &lt;- lm(y3 ~ x3, data=anscombe)\nlm4 &lt;- lm(y4 ~ x4, data=anscombe)\n\n# Compare model coefficients\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n}\n\n# Show coefficients are identical\nsapply(mods, coef)\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\n\n\n\n\n\n# Set up plotting layout\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma = c(0, 0, 2, 0))\n\n# Plot all four datasets with regression lines\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13),\n       main = paste(\"Dataset\", i))\n  abline(mods[[i]], col = \"blue\", lwd = 2)\n}\nmtext(\"Anscombe's 4 Regression Data Sets\", outer = TRUE, cex = 1.5)\n\n\n\n\nAnscombe’s Quartet: Four datasets with identical summary statistics but very different patterns\n\n\n\npar(op)\n\n\n\n\nThe visualization reveals four very different relationships:\n\nDataset 1: Perfect linear relationship\nDataset 2: Clear non-linear (curved) relationship\n\nDataset 3: Linear relationship with one outlier\nDataset 4: No relationship except for one influential point\n\nDespite these dramatic differences, all four datasets have: - Same mean for x and y - Same correlation coefficient - Same regression line - Same R-squared value\nThis demonstrates why visualization is essential for understanding data patterns that summary statistics alone cannot reveal."
  },
  {
    "objectID": "Data_Visualization/Assignments/Assignment1.html#analyzing-anscombes-plots",
    "href": "Data_Visualization/Assignments/Assignment1.html#analyzing-anscombes-plots",
    "title": "Assignment 1: Data Visualization",
    "section": "",
    "text": "Anscombe’s Quartet teaches us that data can look the same in numbers but tell very different stories when you make a graph. All four datasets have the same averages, correlations, and regression lines, but the plots show one is a straight line, another is curved, and others are shaped by outliers.\nThe problem: If we only look at numbers, we may miss these hidden patterns and make wrong conclusions.\nThe solution: Always graph the data before and after running models. Simple plots like scatterplots can reveal issues like outliers, non-linear trends, or unusual points.\n\n\n\n# Load Anscombe's data\ndata(anscombe)\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n\n\n\n\n\n# Create four model objects\nlm1 &lt;- lm(y1 ~ x1, data=anscombe)\nlm2 &lt;- lm(y2 ~ x2, data=anscombe)\nlm3 &lt;- lm(y3 ~ x3, data=anscombe)\nlm4 &lt;- lm(y4 ~ x4, data=anscombe)\n\n# Compare model coefficients\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n}\n\n# Show coefficients are identical\nsapply(mods, coef)\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\n\n\n\n\n\n# Set up plotting layout\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma = c(0, 0, 2, 0))\n\n# Plot all four datasets with regression lines\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13),\n       main = paste(\"Dataset\", i))\n  abline(mods[[i]], col = \"blue\", lwd = 2)\n}\nmtext(\"Anscombe's 4 Regression Data Sets\", outer = TRUE, cex = 1.5)\n\n\n\n\nAnscombe’s Quartet: Four datasets with identical summary statistics but very different patterns\n\n\n\npar(op)\n\n\n\n\nThe visualization reveals four very different relationships:\n\nDataset 1: Perfect linear relationship\nDataset 2: Clear non-linear (curved) relationship\n\nDataset 3: Linear relationship with one outlier\nDataset 4: No relationship except for one influential point\n\nDespite these dramatic differences, all four datasets have: - Same mean for x and y - Same correlation coefficient - Same regression line - Same R-squared value\nThis demonstrates why visualization is essential for understanding data patterns that summary statistics alone cannot reveal."
  },
  {
    "objectID": "Data_Visualization/Assignments/Assignment1.html#changing-color-in-fall-script",
    "href": "Data_Visualization/Assignments/Assignment1.html#changing-color-in-fall-script",
    "title": "Assignment 1: Data Visualization",
    "section": "2. Changing Color in Fall Script",
    "text": "2. Changing Color in Fall Script\n[This section will be completed in the next iteration]"
  },
  {
    "objectID": "Data_Visualization/Assignments/Assignment1.html#critique-of-the-plot-lessons-from-nathan-yau",
    "href": "Data_Visualization/Assignments/Assignment1.html#critique-of-the-plot-lessons-from-nathan-yau",
    "title": "Assignment 1",
    "section": "",
    "text": "This plot tries to show too many things at once—different contrasts, shapes, colors, and line styles—making it cluttered and hard to read.\nAs Nathan Yau emphasizes, a good visualization should highlight the story clearly, but here the message is buried under visual noise.\nProblems in the plot:\n- Long inline labels crowd the chart.\n- The zero line (a key reference) is not emphasized enough.\nCleaner design would:\n- Reduce the number of comparisons per plot.\n- Use consistent symbols.\n- Move labels to a legend.\n- Highlight the reference line.\nThis would make the main story—about winners, losers, and economic perceptions—much easier to see."
  },
  {
    "objectID": "Data_Visualization/Assignments/Assignment1.html#reflections",
    "href": "Data_Visualization/Assignments/Assignment1.html#reflections",
    "title": "Assignment 1",
    "section": "Reflections",
    "text": "Reflections\n\nAI is not just about replacing workers; it’s about empowering them with better tools.\nCollaborative AI means machines handle repetitive tasks while humans focus on higher-value work.\nMany panic about job loss, but the real challenge is learning AI’s rudiments and embracing its advantages."
  },
  {
    "objectID": "Data_Visualization/Assignments/Assignment1.html#key-lessons",
    "href": "Data_Visualization/Assignments/Assignment1.html#key-lessons",
    "title": "Assignment 1",
    "section": "Key Lessons",
    "text": "Key Lessons\n\nEmpowerment, not replacement.\n\nCollaboration between humans and machines.\n\nOvercoming fear of AI through adaptation.\n\nTrust and transparency for adoption."
  },
  {
    "objectID": "Data_Visualization/Assignments/Assignment1.html#conclusion",
    "href": "Data_Visualization/Assignments/Assignment1.html#conclusion",
    "title": "Assignment 1",
    "section": "Conclusion",
    "text": "Conclusion\nIndustrial AI represents transformation, not displacement.\nThe future of work is collaboration where both humans and machines thrive."
  },
  {
    "objectID": "Assignment1.html#q1.-analyzing-anscombes-plots-1",
    "href": "Assignment1.html#q1.-analyzing-anscombes-plots-1",
    "title": "Assignment 1",
    "section": "Q1. Analyzing Anscombe’s Plots",
    "text": "Q1. Analyzing Anscombe’s Plots\nAnscombe’s Quartet shows that datasets can share nearly identical summary statistics (means, variances, correlations, and regression lines) yet have very different relationships when graphed. One series is roughly linear with noise, another is clearly non-linear (curved), another is driven by an outlier, and the last has vertical clustering forced by a high-leverage point.\nWhy this matters: Relying only on summary numbers can be misleading.\nBest practice: Always visualize the data (e.g., scatterplots) before and after modeling to catch outliers/high-leverage points, non-linear patterns, and clusters.\n```{r setup, include=FALSE} knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)"
  },
  {
    "objectID": "Data_Visualization/Assignments/Assignment1.html#critique-of-plot-design-nathan-yau-principles",
    "href": "Data_Visualization/Assignments/Assignment1.html#critique-of-plot-design-nathan-yau-principles",
    "title": "Assignment 1: Data Visualization",
    "section": "3. Critique of Plot Design (Nathan Yau Principles)",
    "text": "3. Critique of Plot Design (Nathan Yau Principles)\n[This section will be completed in the next iteration]"
  }
]